{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from data import *\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = tf.keras.initializers.RandomNormal(mean=0., stddev=1.)\n",
    "def discriminator_bad(dim_length,d=32,input_shape=(64,64,1),name='discriminator',output_dim=10):\n",
    "    dims=[d *(2**i) for i in range(2,2+dim_length)]\n",
    "    img_inputs = keras.Input(shape=(input_shape))\n",
    "    x = layers.Conv2D(d, (4, 4), strides=(2, 2), padding=\"same\",kernel_initializer=initializer)(img_inputs)\n",
    "    x=layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    for dim in dims:\n",
    "        x = layers.Conv2D(d, (4, 4), strides=(2, 2), padding=\"same\",kernel_initializer=initializer)(x)\n",
    "        x= layers.BatchNormalization()(x)\n",
    "        x=layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    binary_x =layers.Conv2D(d, (4,4),strides=(2,2),kernel_initializer=initializer)(x)\n",
    "    binary_x=layers.Flatten(name='binary_flatten')(binary_x)\n",
    "    binary_output = layers.Dense(1,name='binary_output')(binary_x)\n",
    "\n",
    "    multiclass_x=layers.Dense(d,kernel_initializer=initializer)(x)\n",
    "    mutliclass_x=layers.Conv2D(dims[-1], (4,4),strides=(2,2),kernel_initializer=initializer)(multiclass_x)\n",
    "    multiclass_x=layers.Flatten(name='multiclass_flatten')(multiclass_x)\n",
    "    mutlticlass_output=layers.Dense(output_dim,name='multiclass_output')(multiclass_x)\n",
    "    model = keras.Model(inputs=img_inputs, outputs=[binary_output,mutlticlass_output], name=name)\n",
    "    return model\n",
    "\n",
    "def discriminator(input_shape=(64,64,1),name='discriminator',output_dim=10):\n",
    "    img_inputs = keras.Input(shape=(input_shape))\n",
    "    d=input_shape[0]\n",
    "    #x=layers.Flatten()(img_inputs)\n",
    "    x=layers.Conv2D(16, (4, 4), strides=(2, 2), padding=\"same\")(img_inputs)\n",
    "    x=layers.LeakyReLU(alpha=.2)(x)\n",
    "    x= layers.BatchNormalization()(x)\n",
    "    x=layers.Conv2D(32, (4, 4), strides=(2, 2), padding=\"same\")(x)\n",
    "    x=layers.LeakyReLU(alpha=.2)(x)\n",
    "    x= layers.BatchNormalization()(x)\n",
    "    x=layers.Conv2D(64, (4, 4), strides=(2, 2), padding=\"same\")(x)\n",
    "    x=layers.LeakyReLU(alpha=.2)(x)\n",
    "    x= layers.BatchNormalization()(x)\n",
    "    x=layers.Flatten()(x)\n",
    "    #binary_x=layers.Flatten(name='binary_flatten')(x)\n",
    "    binary_output = layers.Dense(1,name='binary_output')(x)\n",
    "    #multiclass_x=layers.Dense(,kernel_initializer=initializer)(x)\n",
    "    #multiclass_x=layers.Flatten(name='multiclass_flatten')(multiclass_x)\n",
    "    mutlticlass_output=layers.Dense(output_dim,name='multiclass_output')(x)\n",
    "    model = keras.Model(inputs=img_inputs, outputs=[binary_output,mutlticlass_output], name=name)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^^The above functions define a discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 17.30it/s]\n"
     ]
    }
   ],
   "source": [
    "d=dataset_limited(['cubism'],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset_limited is defined in data.py; it just gets the feature maps (represented as numpy arrays) for the artistic genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "dick=discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_97 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 32, 32, 16)   272         input_97[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_136 (LeakyReLU)     (None, 32, 32, 16)   0           conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 32, 32, 16)   64          leaky_re_lu_136[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 16, 16, 32)   8224        batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_137 (LeakyReLU)     (None, 16, 16, 32)   0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 16, 16, 32)   128         leaky_re_lu_137[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 8, 8, 64)     32832       batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_138 (LeakyReLU)     (None, 8, 8, 64)     0           conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 8, 8, 64)     256         leaky_re_lu_138[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_66 (Flatten)            (None, 4096)         0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "binary_output (Dense)           (None, 1)            4097        flatten_66[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiclass_output (Dense)       (None, 10)           40970       flatten_66[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 86,843\n",
      "Trainable params: 86,619\n",
      "Non-trainable params: 224\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dick.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator():\n",
    "    latent_dim = 128\n",
    "    generator = keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=(latent_dim,)),\n",
    "            # We want to generate 128 coefficients to reshape into a 7x7x128 map\n",
    "            layers.Dense(8 * 8 * 128),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Reshape((8, 8, 128)),\n",
    "            layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.Conv2D(1, (8, 8), padding=\"same\", activation=\"sigmoid\"),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.BatchNormalization(name=style_blocks[0]),\n",
    "            layers.UpSampling2D(),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.BatchNormalization(name=style_blocks[1]),\n",
    "            layers.UpSampling2D(),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.BatchNormalization(name=style_blocks[2]),\n",
    "            layers.UpSampling2D(),\n",
    "            layers.LeakyReLU(alpha=0.2),\n",
    "            layers.BatchNormalization(name=style_blocks[3]),\n",
    "            layers.Conv2D(1, (2,2), padding=\"same\", activation=\"sigmoid\"),\n",
    "            layers.LeakyReLU(alpha=0.2,name=style_blocks[4])\n",
    "        ],\n",
    "        name=\"generator\",\n",
    "    )\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A basic generator function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 25.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 25.65it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 27.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 22.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 25.02it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 24.12it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 24.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 30.61it/s]\n"
     ]
    }
   ],
   "source": [
    "genres=random_genres(8)\n",
    "labels,matrices=dataset_batched(genres,limit=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random_genres is a function defined in extras.py; it just gets a bunch of random genres. dataset_batched is defined in data.py, it just gets the labels (if a painting is in 'cubism', label =cubism, represented as a one-hot encoding vector) and numpy representations of the paintings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrices_zipped=tf.data.Dataset.zip(tuple(m for m in matrices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(keras.Model):\n",
    "    def __init__(self, discriminators, generator, latent_dim):\n",
    "        super(GAN, self).__init__()\n",
    "        self.discriminators = discriminators\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, binary_loss_fn,multiclass_loss_fn):\n",
    "        super(GAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.binary_loss_fn = binary_loss_fn\n",
    "        self.multiclass_loss_fn = multiclass_loss_fn\n",
    "\n",
    "    def train_step(self, labels_multiclass,matrices,batch_size):\n",
    "        #fake images\n",
    "        net_loss=[]\n",
    "        random_latent_vectors = [tf.random.normal(shape=(1, self.latent_dim)) for _ in range(batch_size)]\n",
    "        # Decode them to fake images\n",
    "        generated_images = self.generator(random_latent_vectors)\n",
    "        ret={}\n",
    "        for real_mats,block,discriminator in zip(matrices,style_blocks,self.discriminators):\n",
    "            func=keras.backend.function([self.generator.get_layer(index=0).input], \n",
    "                                        self.generator.get_layer(name=block).output)\n",
    "            gen_mats=[func(vector)[0] for vector in random_latent_vectors]\n",
    "            #print(gen_mats[0].shape)\n",
    "            #print(real_mats[0].shape)\n",
    "            combined_mats = tf.concat([gen_mats, real_mats], axis=0)\n",
    "            # Assemble labels discriminating real from fake images\n",
    "            labels_binary = tf.concat(\n",
    "                [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "            )\n",
    "            # Add random noise to the labels - important trick!\n",
    "            labels_binary += 0.05 * tf.random.uniform(tf.shape(labels_binary))\n",
    "            \n",
    "            # Train the discriminator\n",
    "            with tf.GradientTape() as tape:\n",
    "                pred_binary,pred_multiclass = discriminator(combined_mats)\n",
    "                pred_multiclass=pred_multiclass[-len(real_mats):]\n",
    "                d_loss = self.binary_loss_fn(labels_binary, pred_binary)+self.multiclass_loss_fn(labels_multiclass,pred_multiclass)\n",
    "            grads = tape.gradient(d_loss, discriminator.trainable_weights)\n",
    "            self.d_optimizer.apply_gradients(\n",
    "                zip(grads, discriminator.trainable_weights)\n",
    "            )\n",
    "            net_loss.append(d_loss)\n",
    "        return net_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defines the GAN with its own training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes=[(64, 64,1), (128, 128,1), (256, 256,1), (512, 512, 1), (512, 512,1)]\n",
    "discriminators=[discriminator(input_shape=s,name=str(s),output_dim=len(genres)) for s in shapes]\n",
    "generator=make_generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Five discriminators, since we're using feature maps from 5 different layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"(64, 64, 1)\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_98 (InputLayer)           [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 32, 32, 16)   272         input_98[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_139 (LeakyReLU)     (None, 32, 32, 16)   0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 32, 32, 16)   64          leaky_re_lu_139[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 16, 16, 32)   8224        batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_140 (LeakyReLU)     (None, 16, 16, 32)   0           conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 16, 16, 32)   128         leaky_re_lu_140[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 8, 8, 64)     32832       batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_141 (LeakyReLU)     (None, 8, 8, 64)     0           conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 8, 8, 64)     256         leaky_re_lu_141[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_67 (Flatten)            (None, 4096)         0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "binary_output (Dense)           (None, 1)            4097        flatten_67[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiclass_output (Dense)       (None, 8)            32776       flatten_67[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 78,649\n",
      "Trainable params: 78,425\n",
      "Non-trainable params: 224\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"(128, 128, 1)\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_99 (InputLayer)           [(None, 128, 128, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 64, 64, 16)   272         input_99[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_142 (LeakyReLU)     (None, 64, 64, 16)   0           conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 64, 64, 16)   64          leaky_re_lu_142[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 32, 32, 32)   8224        batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_143 (LeakyReLU)     (None, 32, 32, 32)   0           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 32, 32, 32)   128         leaky_re_lu_143[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 16, 16, 64)   32832       batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_144 (LeakyReLU)     (None, 16, 16, 64)   0           conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 16, 16, 64)   256         leaky_re_lu_144[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_68 (Flatten)            (None, 16384)        0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "binary_output (Dense)           (None, 1)            16385       flatten_68[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiclass_output (Dense)       (None, 8)            131080      flatten_68[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 189,241\n",
      "Trainable params: 189,017\n",
      "Non-trainable params: 224\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"(256, 256, 1)\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_100 (InputLayer)          [(None, 256, 256, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 128, 128, 16) 272         input_100[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_145 (LeakyReLU)     (None, 128, 128, 16) 0           conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 128, 128, 16) 64          leaky_re_lu_145[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 64, 64, 32)   8224        batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_146 (LeakyReLU)     (None, 64, 64, 32)   0           conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 64, 64, 32)   128         leaky_re_lu_146[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 32, 32, 64)   32832       batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_147 (LeakyReLU)     (None, 32, 32, 64)   0           conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 32, 32, 64)   256         leaky_re_lu_147[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_69 (Flatten)            (None, 65536)        0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "binary_output (Dense)           (None, 1)            65537       flatten_69[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiclass_output (Dense)       (None, 8)            524296      flatten_69[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 631,609\n",
      "Trainable params: 631,385\n",
      "Non-trainable params: 224\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"(512, 512, 1)\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_101 (InputLayer)          [(None, 512, 512, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 256, 256, 16) 272         input_101[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_148 (LeakyReLU)     (None, 256, 256, 16) 0           conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 256, 256, 16) 64          leaky_re_lu_148[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 128, 128, 32) 8224        batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_149 (LeakyReLU)     (None, 128, 128, 32) 0           conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 128, 128, 32) 128         leaky_re_lu_149[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 64, 64, 64)   32832       batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_150 (LeakyReLU)     (None, 64, 64, 64)   0           conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 64, 64, 64)   256         leaky_re_lu_150[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_70 (Flatten)            (None, 262144)       0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "binary_output (Dense)           (None, 1)            262145      flatten_70[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiclass_output (Dense)       (None, 8)            2097160     flatten_70[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 2,401,081\n",
      "Trainable params: 2,400,857\n",
      "Non-trainable params: 224\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"(512, 512, 1)\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_102 (InputLayer)          [(None, 512, 512, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 256, 256, 16) 272         input_102[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_151 (LeakyReLU)     (None, 256, 256, 16) 0           conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 256, 256, 16) 64          leaky_re_lu_151[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 128, 128, 32) 8224        batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_152 (LeakyReLU)     (None, 128, 128, 32) 0           conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 128, 128, 32) 128         leaky_re_lu_152[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 64, 64, 64)   32832       batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_153 (LeakyReLU)     (None, 64, 64, 64)   0           conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 64, 64, 64)   256         leaky_re_lu_153[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_71 (Flatten)            (None, 262144)       0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "binary_output (Dense)           (None, 1)            262145      flatten_71[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "multiclass_output (Dense)       (None, 8)            2097160     flatten_71[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 2,401,081\n",
      "Trainable params: 2,400,857\n",
      "Non-trainable params: 224\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for d in discriminators:\n",
    "    d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = GAN(discriminators=discriminators, generator=generator, latent_dim=latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=0.003),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
    "    binary_loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    multiclass_loss_fn=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start epoch 0\n",
      "discriminator loss at step 0: 23091.149077415466\n",
      "discriminator loss at step 1: 23543.658094406128\n",
      "discriminator loss at step 2: 1327523.0825195312\n",
      "discriminator loss at step 3: 2446776.3416748047\n",
      "discriminator loss at step 4: 3947724.1041259766\n",
      "discriminator loss at step 5: 1375585.420135498\n",
      "discriminator loss at step 6: 5074869.900695801\n",
      "discriminator loss at step 7: 1500128.050857544\n",
      "discriminator loss at step 8: 7285997.040222168\n",
      "discriminator loss at step 9: 916189.2157592773\n",
      "discriminator loss at step 10: 1837345.3723144531\n",
      "discriminator loss at step 11: 3749354.8834228516\n",
      "discriminator loss at step 12: 4873091.0361328125\n",
      "discriminator loss at step 13: 3799913.098388672\n",
      "discriminator loss at step 14: 4094925.545639038\n",
      "discriminator loss at step 15: 2693076.171890259\n",
      "\n",
      "Start epoch 1\n",
      "discriminator loss at step 0: 234254.8247680664\n",
      "discriminator loss at step 1: 111770.27681732178\n",
      "discriminator loss at step 2: 10335151.901428223\n",
      "discriminator loss at step 3: 3005288.418899536\n",
      "discriminator loss at step 4: 1510350.380859375\n",
      "discriminator loss at step 5: 149329.65984344482\n",
      "discriminator loss at step 6: 13691228.701049805\n",
      "discriminator loss at step 7: 3412329.7349243164\n",
      "discriminator loss at step 8: 9255628.613708496\n",
      "discriminator loss at step 9: 2805600.471069336\n",
      "discriminator loss at step 10: 11541078.046508789\n",
      "discriminator loss at step 11: 4335802.056808472\n",
      "discriminator loss at step 12: 4507115.080810547\n",
      "discriminator loss at step 13: 75976.56784057617\n",
      "discriminator loss at step 14: 2514451.7463378906\n",
      "discriminator loss at step 15: 114291.01971435547\n",
      "\n",
      "Start epoch 2\n",
      "discriminator loss at step 0: 31936237.823486328\n",
      "discriminator loss at step 1: 426551.30432128906\n",
      "discriminator loss at step 2: 22663754.992919922\n",
      "discriminator loss at step 3: 7406354.789825439\n",
      "discriminator loss at step 4: 6337890.427215576\n",
      "discriminator loss at step 5: 777536.3804550171\n",
      "discriminator loss at step 6: 9246136.560707092\n",
      "discriminator loss at step 7: 2736248.0270347595\n",
      "discriminator loss at step 8: 24508722.39453125\n",
      "discriminator loss at step 9: 3805595.1540527344\n",
      "discriminator loss at step 10: 964524.6604003906\n",
      "discriminator loss at step 11: 750509.9108886719\n",
      "discriminator loss at step 12: 53228609.88647461\n",
      "discriminator loss at step 13: 11706800.450134277\n",
      "discriminator loss at step 14: 3244422.3654785156\n",
      "discriminator loss at step 15: 866032.8956298828\n",
      "\n",
      "Start epoch 3\n",
      "discriminator loss at step 0: 28970049.998535156\n",
      "discriminator loss at step 1: 19703901.489013672\n",
      "discriminator loss at step 2: 30048957.696777344\n",
      "discriminator loss at step 3: 987467.4144287109\n",
      "discriminator loss at step 4: 34417426.28326416\n",
      "discriminator loss at step 5: 1604801.1276855469\n",
      "discriminator loss at step 6: 326210005.5357361\n",
      "discriminator loss at step 7: 93730407.48275757\n",
      "discriminator loss at step 8: 4093647.0844726562\n",
      "discriminator loss at step 9: 4349971.603759766\n",
      "discriminator loss at step 10: 254476138.49169922\n",
      "discriminator loss at step 11: 68485400.5834961\n",
      "discriminator loss at step 12: 260897855.01037598\n",
      "discriminator loss at step 13: 192758711.16851807\n",
      "discriminator loss at step 14: 81511839.47558594\n",
      "discriminator loss at step 15: 39925590.54968262\n",
      "\n",
      "Start epoch 4\n",
      "discriminator loss at step 0: 10013052.794921875\n",
      "discriminator loss at step 1: 3173439.803955078\n",
      "discriminator loss at step 2: 92194344.16296387\n",
      "discriminator loss at step 3: 24812801.646514893\n",
      "discriminator loss at step 4: 130882872.94433594\n",
      "discriminator loss at step 5: 26271195.671142578\n",
      "discriminator loss at step 6: 50281223.98300171\n",
      "discriminator loss at step 7: 1425276.7788009644\n",
      "discriminator loss at step 8: 76019708.60791016\n",
      "discriminator loss at step 9: 2674814.803466797\n",
      "discriminator loss at step 10: 409598137.15437317\n",
      "discriminator loss at step 11: 67511086.3449707\n",
      "discriminator loss at step 12: 112836349.65405273\n",
      "discriminator loss at step 13: 102788375.52807617\n",
      "discriminator loss at step 14: 8424281.913452148\n",
      "discriminator loss at step 15: 626412.2479858398\n",
      "\n",
      "Start epoch 5\n",
      "discriminator loss at step 0: 38434294.7409668\n",
      "discriminator loss at step 1: 13627754.095859528\n",
      "discriminator loss at step 2: 251041366.9530182\n",
      "discriminator loss at step 3: 141987891.68902588\n",
      "discriminator loss at step 4: 44669904.529052734\n",
      "discriminator loss at step 5: 3717361.7513427734\n",
      "discriminator loss at step 6: 318296914.3880005\n",
      "discriminator loss at step 7: 4412170.869384766\n",
      "discriminator loss at step 8: 495368666.3774414\n",
      "discriminator loss at step 9: 2175067.8115234375\n",
      "discriminator loss at step 10: 1101104431.902832\n",
      "discriminator loss at step 11: 286130709.1611328\n",
      "discriminator loss at step 12: 6768992.740966797\n",
      "discriminator loss at step 13: 5776819.9920043945\n",
      "discriminator loss at step 14: 625579469.2814941\n",
      "discriminator loss at step 15: 470661517.98291016\n",
      "\n",
      "Start epoch 6\n",
      "discriminator loss at step 0: 202250094.31152344\n",
      "discriminator loss at step 1: 158467416.05419922\n",
      "discriminator loss at step 2: 276217469.9210205\n",
      "discriminator loss at step 3: 125429653.47872925\n",
      "discriminator loss at step 4: 92508157.73828125\n",
      "discriminator loss at step 5: 19792642.778076172\n",
      "discriminator loss at step 6: 324545468.49487305\n",
      "discriminator loss at step 7: 189230508.6939087\n",
      "discriminator loss at step 8: 204485773.34552002\n",
      "discriminator loss at step 9: 216059772.82470703\n",
      "discriminator loss at step 10: 495024114.62475586\n",
      "discriminator loss at step 11: 329127803.93310547\n",
      "discriminator loss at step 12: 177304837.68774414\n",
      "discriminator loss at step 13: 191514554.51800537\n",
      "discriminator loss at step 14: 135346797.32836914\n",
      "discriminator loss at step 15: 20714658.248413086\n",
      "\n",
      "Start epoch 7\n",
      "discriminator loss at step 0: 41083153.66443634\n",
      "discriminator loss at step 1: 6434474.162719727\n",
      "discriminator loss at step 2: 180276468.3421631\n",
      "discriminator loss at step 3: 110283301.73809814\n",
      "discriminator loss at step 4: 65181465.13354492\n",
      "discriminator loss at step 5: 1741701.3035888672\n",
      "discriminator loss at step 6: 192031327.15551758\n",
      "discriminator loss at step 7: 143080233.28979492\n",
      "discriminator loss at step 8: 55762881.25097656\n",
      "discriminator loss at step 9: 6828974.499267578\n",
      "discriminator loss at step 10: 187886111.0863037\n",
      "discriminator loss at step 11: 166461223.4885254\n",
      "discriminator loss at step 12: 196828703.20111084\n",
      "discriminator loss at step 13: 102579406.57336426\n",
      "discriminator loss at step 14: 134530542.9920044\n",
      "discriminator loss at step 15: 83383608.05236816\n",
      "\n",
      "Start epoch 8\n",
      "discriminator loss at step 0: 38329971.61639404\n",
      "discriminator loss at step 1: 29432474.004882812\n",
      "discriminator loss at step 2: 57912536.310791016\n",
      "discriminator loss at step 3: 7243077.436889648\n",
      "discriminator loss at step 4: 124686056.63586426\n",
      "discriminator loss at step 5: 92563595.61279297\n",
      "discriminator loss at step 6: 349279175.72875977\n",
      "discriminator loss at step 7: 300062385.3603821\n",
      "discriminator loss at step 8: 466133613.27098083\n",
      "discriminator loss at step 9: 251136404.74116516\n",
      "discriminator loss at step 10: 60890047.35487366\n",
      "discriminator loss at step 11: 92034122.21962547\n",
      "discriminator loss at step 12: 12537053.90699768\n",
      "discriminator loss at step 13: 2773919.2041244507\n",
      "discriminator loss at step 14: 219697094.92974854\n",
      "discriminator loss at step 15: 46442267.89709473\n",
      "\n",
      "Start epoch 9\n",
      "discriminator loss at step 0: 28727697.914611816\n",
      "discriminator loss at step 1: 27863495.041015625\n",
      "discriminator loss at step 2: 56718018.14123535\n",
      "discriminator loss at step 3: 45851479.07922363\n",
      "discriminator loss at step 4: 4369162.8068237305\n",
      "discriminator loss at step 5: 2618928.8294677734\n",
      "discriminator loss at step 6: 58857610.737091064\n",
      "discriminator loss at step 7: 48843568.31176758\n",
      "discriminator loss at step 8: 153706259.3036251\n",
      "discriminator loss at step 9: 125542260.74112701\n",
      "discriminator loss at step 10: 31438985.721069336\n",
      "discriminator loss at step 11: 3724949.136077881\n",
      "discriminator loss at step 12: 120381631.6149292\n",
      "discriminator loss at step 13: 18063741.308929443\n",
      "discriminator loss at step 14: 241081491.62561035\n",
      "discriminator loss at step 15: 86143834.50463867\n",
      "\n",
      "Start epoch 10\n",
      "discriminator loss at step 0: 42871514.60227966\n",
      "discriminator loss at step 1: 38781961.773498535\n",
      "discriminator loss at step 2: 95372599.22317123\n",
      "discriminator loss at step 3: 59178535.21544647\n",
      "discriminator loss at step 4: 58988860.845565796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss at step 5: 24847959.281723022\n",
      "discriminator loss at step 6: 4146589.866882324\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_FallbackException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\jlbak\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mconcat_v2\u001b[1;34m(values, axis, name)\u001b[0m\n\u001b[0;32m   1169\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1170\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   1171\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ConcatV2\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31m_FallbackException\u001b[0m: This function does not handle the case of the path where all inputs are not already EagerTensors.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-160-a0fd3a9e9184>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmatrices_zipped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;31m# Train the discriminator & generator on one batch of real images.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0md_loss\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"discriminator loss at step {}: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;32min\u001b[0m \u001b[0md_loss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-143-8c8ef9334a99>\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self, labels_multiclass, matrices, batch_size)\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;31m#print(gen_mats[0].shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[1;31m#print(real_mats[0].shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m             \u001b[0mcombined_mats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgen_mats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal_mats\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m             \u001b[1;31m# Assemble labels discriminating real from fake images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             labels_binary = tf.concat(\n",
      "\u001b[1;32mc:\\users\\jlbak\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jlbak\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(values, axis, name)\u001b[0m\n\u001b[0;32m   1604\u001b[0m           dtype=dtypes.int32).get_shape().assert_has_rank(0)\n\u001b[0;32m   1605\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1606\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jlbak\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mconcat_v2\u001b[1;34m(values, axis, name)\u001b[0m\n\u001b[0;32m   1174\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1176\u001b[1;33m         return concat_v2_eager_fallback(\n\u001b[0m\u001b[0;32m   1177\u001b[0m             values, axis, name=name, ctx=_ctx)\n\u001b[0;32m   1178\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jlbak\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mconcat_v2_eager_fallback\u001b[1;34m(values, axis, name, ctx)\u001b[0m\n\u001b[0;32m   1207\u001b[0m         \"'concat_v2' Op, not %r.\" % values)\n\u001b[0;32m   1208\u001b[0m   \u001b[0m_attr_N\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1209\u001b[1;33m   \u001b[0m_attr_T\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs_to_matching_eager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1210\u001b[0m   \u001b[0m_attr_Tidx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs_to_matching_eager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1211\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jlbak\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36margs_to_matching_eager\u001b[1;34m(l, ctx, default_dtype)\u001b[0m\n\u001b[0;32m    265\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m     \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m   \u001b[1;31m# TODO(slebedev): consider removing this as it leaks a Keras concept.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jlbak\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    265\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m     \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m   \u001b[1;31m# TODO(slebedev): consider removing this as it leaks a Keras concept.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jlbak\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1340\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1341\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jlbak\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    319\u001b[0m                                          as_ref=False):\n\u001b[0;32m    320\u001b[0m   \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jlbak\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m   \"\"\"\n\u001b[1;32m--> 261\u001b[1;33m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[0;32m    262\u001b[0m                         allow_broadcast=True)\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jlbak\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    268\u001b[0m   \u001b[0mctx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 270\u001b[1;33m     \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    271\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs=20\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart epoch\", epoch)\n",
    "\n",
    "    step=0\n",
    "    for step,(l,m) in enumerate(zip(labels,matrices_zipped)):\n",
    "        # Train the discriminator & generator on one batch of real images.\n",
    "        d_loss= gan.train_step(l,m,10)\n",
    "        print(\"discriminator loss at step {}: {}\".format(step,sum([(np.round(loss,3)) for loss in d_loss])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
